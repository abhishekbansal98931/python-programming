{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading from a text file\n",
    "\n",
    "filename = 'abc.text'\n",
    "\n",
    "#Open file connection\n",
    "file = open(filename, mode = 'r')   # r is to read, w is to write\n",
    "text = file.read\n",
    "\n",
    "#Close file connection\n",
    "file.close()\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoid having to close the file\n",
    "\n",
    "with open('abc.txt', 'r') as file:\n",
    "    print(file.read())\n",
    "    \n",
    "#this allows for creating a context and once we move out of context the file is no longer open\n",
    "#that's why 'with' is called as the context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a line with '!' gives complete system shell access\n",
    "\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking whether a file is closed\n",
    "print(file.closed)\n",
    "\n",
    "#readline method will print the first line, using it twice will print the 2nd line as well\n",
    "with open('abc.txt', 'r') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "#this will print the first 3 lines of the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing flat files using NumPy (loadtxt() and genfromtxt())\n",
    "\n",
    "import numpy as np\n",
    "filename = 'MNIST.txt'\n",
    "data = np.loadtxt(filename, delimiter=',') #other arguments can be delimiter = '\\t', skiprows = 1, usecols=[0,2], dtype = str (this will ensure that everything is loaded as strings)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "digits = np.loadtxt('digits.csv', delimiter=',')\n",
    "print(type(digits))\n",
    "\n",
    "im = digits[21, 1:]\n",
    "im_sq = np.reshape(im, (28,28))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data which has different datatypes in different columns into structured array\n",
    "\n",
    "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None) #it will directly \n",
    "np.shape(data)\n",
    "\n",
    "#np.recfromcsv() is similar to genfromtxt() except that it has these default values delimiter=',',dtype=none, names=True\n",
    "data = np.recfromcsv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing flat files using Pandas\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()\n",
    "\n",
    "#Converting it into a numpy array\n",
    "\n",
    "data = pd.read_csv('titanic.csv', nrows=5, header=None)\n",
    "data_array = data.values\n",
    "print(type(data_array))\n",
    "\n",
    "#Removing comments and missing values\n",
    "import matplotlib.pyplot as plt\n",
    "file = 'titanic_corrupt.txt'\n",
    "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing') #tab delimited file, has comments starting from # and \n",
    "#has Nothing as a string where values are missing, na_values takes a list of strings where values are missing can be NA, NaN\n",
    "print(data.head())\n",
    "# Plot 'Age' variable in a histogram\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduction to other file types\n",
    "#Excel spreadsheets, MATLAB files, SAS files, Stata files, HDF5, pickled files (file type native to Python eg: dictionaries, list and also json)\n",
    "\n",
    "import pickle\n",
    "with open('pickled_fruit.pkl', 'rb') as file:  #rb means read only binary file which means it's computer readable and not human readable\n",
    "    data = pickle.load(file)\n",
    "print(data)\n",
    "print(type(data))\n",
    "\n",
    "Output: {'peaches': 13, 'apples': 4, 'oranges': 11}\n",
    "    <class 'dict'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing excel spreadsheets\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.ExcelFile('urbanpop.xlsx')\n",
    "print(data.sheet_names)\n",
    "\n",
    "#Output: ['1960-1966', '1967-1974', '1975-2011']\n",
    "\n",
    "#Importing individual sheets into dataframes\n",
    "df1 = data.parse('1960-1966') #sheet name, as a string\n",
    "df2 = data.parse(0) #sheet index, as a float\n",
    "df1.head()\n",
    "#df1 = data.parse(0, skiprows=[1], names=['Country', 'AAM due to War (2002)'])\n",
    "#df2 = data.parse(1, usecols=[0], skiprows=[1], names=['Country'])\n",
    "#the arguments needs to be of type list hence the brackets []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing commands like ! ls natively in Python using library os\n",
    "\n",
    "import os\n",
    "wd = os.getcwd()  #current working directory\n",
    "os.listdir(wd)  #outputs the contents of the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing SAS / Stata files using pandas\n",
    "#SAS is Statistical Analysis System. Formats are sas7bdat and sas7bcat (SAS datasets and catalogue files)\n",
    "#Stata is \"Statistics\" + \"data\". Format is dta\n",
    "\n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "with SAS7BDAT('urbanpop.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_stata('urbanpop.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing HDF5 files\n",
    "#HDF5 means Hierarchical Data Format version 5\n",
    "#Standard for storing large quantities of numerical data (gigabytes, terabytes, exabytes)\n",
    "#HDF5 can scale to exabytes\n",
    "\n",
    "import h5py\n",
    "filename = 'xxxx.hdf5'\n",
    "data = h5py.File(filename, 'r') #r is to read\n",
    "print(type(data))\n",
    "\n",
    "Output: <class h5py._hl.files.File'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structure of HDF5 files\n",
    "\n",
    "for key in data.keys():\n",
    "    print(key)\n",
    "\n",
    "Output:\n",
    "    meta\n",
    "    quality\n",
    "    strain\n",
    "\n",
    "#Each of these is an HDF group\n",
    "#meta has the meta data for the file\n",
    "#quality refers to data quality\n",
    "#strain is the data\n",
    "\n",
    "for key in data['meta'].keys():\n",
    "    print(key)\n",
    "    \n",
    "Output: Description\n",
    "        Detector\n",
    "        .. etc.\n",
    "\n",
    "print(data['meta']['description'].value, data['meta']['detector'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing MATLAB files\n",
    "#MATLAB is short form of Matrix Laboratory is a numerical computing environment\n",
    "#saved as .mat files which has collection of objects / variables\n",
    "\n",
    "scipy.io.loadmat() #read .mat files\n",
    "scipy.io.savemat() #write .mat files\n",
    "\n",
    "import scipy.io\n",
    "filename = 'workspace.mat'\n",
    "mat = scipy.io.loadmat(filename)\n",
    "print(type(mat))\n",
    "\n",
    "Output: <class 'dict'>\n",
    "    \n",
    "#keys = MATLAB variable names\n",
    "#values = objects assigned to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduction to relational databases\n",
    "\n",
    "#Here we'll be connecting to a SQLite database\n",
    "#Creating a database engine\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "#this will fire up an sql engine that will communicate our queries to the database\n",
    "\n",
    "#Getting table names\n",
    "table_names = engine.table_names()\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quering relational databases in Python\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "con = engine.connect()    #connect to the engine\n",
    "rs = con.execute(\"SELECT * FROM Orders\")\n",
    "df = pd.DataFrame(rs.fetchall())  #fetchall means fetch all rows\n",
    "df.columns = rs.keys()  #not doing this will not copy column names and will be named 1,2,3....\n",
    "con.close()     #close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the context manager\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///Northwind.sqlite')\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT OrderID, OrderDate, ShipName FROM Orders\")\n",
    "    df = pd.DataFrame(rs.fetchmany(size=5))\n",
    "    df.columns = rs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quering relational databases directly with pandas\n",
    "\n",
    "df = pd.read_sql_query(\"select * from orders\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if two dataframes are exactly the same\n",
    "\n",
    "print(df1.equals(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
